# Analisi Approfondita del Progetto Mistral SQL Assistant

**Data analisi:** 2025-11-14
**Versione progetto:** Analizzata da repository locale

---

## Indice

1. [Scopo del Progetto](#1-scopo-del-progetto)
2. [Struttura Generale del Codebase](#2-struttura-generale-del-codebase)
3. [Componenti Principali e ResponsabilitÃ ](#3-componenti-principali-e-responsabilitÃ )
4. [Architettura del Sistema](#4-architettura-del-sistema)
5. [Autenticazione - Dettagli Tecnici](#5-autenticazione---dettagli-tecnici)
6. [Dipendenze Principali](#6-dipendenze-principali)
7. [Configurazioni e Variabili d'Ambiente](#7-configurazioni-e-variabili-dambiente)
8. [Punti di Ingresso dell'Applicazione](#8-punti-di-ingresso-dellapplicazione)
9. [Schema SQL e Knowledge Base](#9-schema-sql-e-knowledge-base)
10. [Struttura Docker](#10-struttura-docker)
11. [Testing](#11-testing)
12. [Codice di Configurazione QualitÃ ](#12-codice-di-configurazione-qualitÃ )
13. [Riassunto Architetturale](#13-riassunto-architetturale)

---

## 1. SCOPO DEL PROGETTO

**Mistral SQL Assistant** Ã¨ un'applicazione intelligente di generazione di query SQL che combina:
- Un'interfaccia web moderna (Streamlit)
- Modelli di linguaggio (Ollama con Mistral)
- Indici vettoriali persistenti (LlamaIndex)
- Embedding semantici (HuggingFace)

L'applicazione permette agli utenti di chiedere in linguaggio naturale query SQL complesse, che vengono generate automaticamente basandosi su uno schema SQL predefinito.

### Stack Tecnologico

- **Frontend**: Streamlit (framework web Python)
- **LLM**: Ollama + Mistral (eseguito localmente su CPU)
- **Embeddings**: HuggingFace sentence-transformers/all-MiniLM-L6-v2 (GPU/CPU configurabile)
- **Vector Store**: LlamaIndex con persistenza su disco
- **Package Manager**: uv (package manager Python moderno)
- **Containerizzazione**: Docker + Docker Compose

### Caso d'Uso Tipico

```
Utente: "Quanti ordini ho fatto questo mese?"
    â†“
Sistema genera: "SELECT COUNT(*) FROM ordini WHERE EXTRACT(MONTH FROM data) = EXTRACT(MONTH FROM CURRENT_DATE)"
    â†“
Visualizza con syntax highlighting + copy to clipboard
```

---

## 2. STRUTTURA GENERALE DEL CODEBASE

```
c:\Progetti\mistral/
â”œâ”€â”€ src/mistral/                          # Codice sorgente principale
â”‚   â”œâ”€â”€ __init__.py                       # Package metadata
â”‚   â”œâ”€â”€ config.py                         # Configurazioni centralizzate
â”‚   â”œâ”€â”€ core/                             # Logica core
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ engine.py                     # Query engine
â”‚   â”‚   â””â”€â”€ indexer.py                    # Creazione indici vettoriali
â”‚   â”œâ”€â”€ ui/                               # Interfaccia utente
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ app.py                        # App Streamlit principale
â”‚   â”‚   â””â”€â”€ components.py                 # Componenti UI riutilizzabili
â”‚   â””â”€â”€ utils/                            # Utility
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ auth.py                       # Autenticazione HuggingFace
â”œâ”€â”€ tests/                                # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                       # Fixture pytest
â”‚   â”œâ”€â”€ test_auth.py                      # Test autenticazione
â”‚   â””â”€â”€ test_config.py                    # Test configurazione
â”œâ”€â”€ scripts/                              # Script entry points
â”‚   â”œâ”€â”€ run_app.py                        # Avvia app Streamlit
â”‚   â””â”€â”€ create_index.py                   # Crea indice vettoriale
â”œâ”€â”€ data/                                 # Dati persistenti
â”‚   â”œâ”€â”€ schema.sql                        # Schema SQL (knowledge base)
â”‚   â””â”€â”€ db_index/                         # Vector store persistente
â”œâ”€â”€ pyproject.toml                        # Configurazione progetto
â”œâ”€â”€ README.md                             # Documentazione
â”œâ”€â”€ Dockerfile                            # Configurazione container
â”œâ”€â”€ docker-compose.yml                    # Orchestrazione servizi
â”œâ”€â”€ .env                                  # Variabili d'ambiente (production)
â”œâ”€â”€ .env.example                          # Template variabili d'ambiente
â””â”€â”€ .gitignore                            # File ignorati da git
```

### Organizzazione Modulare

Il progetto segue una struttura ben definita:

- **`src/mistral/`**: Tutto il codice sorgente
- **`tests/`**: Suite di test completa con pytest
- **`scripts/`**: Entry points eseguibili
- **`data/`**: Dati persistenti (schema + indici)

---

## 3. COMPONENTI PRINCIPALI E RESPONSABILITÃ€

### 3.1 CONFIG.PY - Configurazioni Centralizzate

**Percorso**: `src/mistral/config.py`

**ResponsabilitÃ **:
- Carica le variabili d'ambiente dal file `.env`
- Centralizza tutte le configurazioni dell'applicazione
- Valida le impostazioni critiche
- Gestisce i path assoluti del progetto

**Parametri configurabili**:

```python
class Config:
    # HuggingFace Configuration
    HUGGINGFACE_TOKEN: str = os.getenv("HUGGINGFACE_TOKEN", "")

    # Device Configuration
    DEVICE: str = os.getenv("DEVICE", "cuda")

    # Ollama Configuration
    OLLAMA_MODEL: str = os.getenv("OLLAMA_MODEL", "mistral")
    OLLAMA_HOST: str = os.getenv("OLLAMA_HOST", "localhost:11434")

    # Embedding Configuration
    EMBEDDING_MODEL: str = os.getenv(
        "EMBEDDING_MODEL",
        "sentence-transformers/all-MiniLM-L6-v2"
    )

    # Vector Store Configuration
    VECTOR_STORE_DIR: Path = Path(os.getenv("VECTOR_STORE_DIR", "./data/db_index"))

    # Streamlit Configuration
    STREAMLIT_SERVER_PORT: int = int(os.getenv("STREAMLIT_SERVER_PORT", "8501"))
    STREAMLIT_SERVER_ADDRESS: str = os.getenv("STREAMLIT_SERVER_ADDRESS", "localhost")
```

**Metodo di validazione**:

```python
@classmethod
def validate(cls) -> None:
    """Validate configuration settings."""
    if not cls.HUGGINGFACE_TOKEN:
        raise ValueError("HUGGINGFACE_TOKEN environment variable is required")

    if not cls.SCHEMA_FILE.exists():
        raise FileNotFoundError(f"Schema file not found: {cls.SCHEMA_FILE}")

    # Create directories if they don't exist
    cls.VECTOR_STORE_DIR.mkdir(parents=True, exist_ok=True)
    cls.DATA_DIR.mkdir(parents=True, exist_ok=True)
```

---

### 3.2 AUTH.PY - Autenticazione HuggingFace

**Percorso**: `src/mistral/utils/auth.py`

**ResponsabilitÃ **:
- Autenticazione con HuggingFace Hub per accedere ai modelli
- Gestione centralizzata dei token
- Logging degli errori di autenticazione

**Funzione principale**:

```python
def authenticate_huggingface(token: Optional[str] = None) -> None:
    """
    Authenticate with HuggingFace Hub.

    Args:
        token: Optional HuggingFace token. If not provided,
               uses token from config.

    Raises:
        ValueError: If no token is available
        Exception: If authentication fails
    """
    hf_token = token or config.HUGGINGFACE_TOKEN

    if not hf_token:
        raise ValueError(
            "HuggingFace token is required. "
            "Set HUGGINGFACE_TOKEN environment variable."
        )

    try:
        login(token=hf_token)
        logger.info("Successfully authenticated with HuggingFace Hub")
    except Exception as e:
        logger.error(f"Failed to authenticate with HuggingFace Hub: {e}")
        raise
```

**Flow di autenticazione**:

1. Accetta token come parametro o da config
2. Valida che il token sia disponibile
3. Chiama `huggingface_hub.login(token)` per l'autenticazione
4. Registra successo/errore nei log

**Quando viene invocata**:
- In `engine.py`: Prima di caricare il query engine
- In `indexer.py`: Prima di creare l'indice vettoriale

---

### 3.3 ENGINE.PY - Query Engine

**Percorso**: `src/mistral/core/engine.py`

**ResponsabilitÃ **:
- Carica e configura il query engine
- Inizializza LLM (Ollama)
- Inizializza embedding model
- Carica l'indice vettoriale persistente
- Fornisce interfaccia per le query

**Funzione principale**:

```python
def load_query_engine() -> object:
    """
    Load and configure the query engine.

    Returns:
        Query engine ready to accept natural language queries

    Raises:
        ValueError: If configuration is invalid
        FileNotFoundError: If vector store doesn't exist
    """
```

**Componenti inizializzati**:

#### 1. Autenticazione

```python
authenticate_huggingface()
```

#### 2. LLM - Language Model (Ollama)

```python
llm = LangChainLLM(llm=Ollama(
    model=config.OLLAMA_MODEL,
    base_url=f"http://{config.OLLAMA_HOST}"
))
```

- Usa Ollama per l'inferenza del modello Mistral
- Eseguito localmente per privacy e performance
- Comunicazione via HTTP API

#### 3. Embedding Model

```python
embed_model = HuggingFaceEmbedding(
    model_name=config.EMBEDDING_MODEL,
    device=config.DEVICE
)
```

- Crea embedding semantici delle query
- Supporta GPU (CUDA) e CPU
- Modello: all-MiniLM-L6-v2 (piccolo e veloce)

#### 4. Service Context

```python
service_context = ServiceContext.from_defaults(
    llm=llm,
    embed_model=embed_model
)
```

- Combina LLM e embedding model
- Centralizza configurazione dei servizi

#### 5. Caricamento Vector Store

```python
storage_context = StorageContext.from_defaults(
    persist_dir=str(config.VECTOR_STORE_DIR)
)
index = load_index_from_storage(
    storage_context=storage_context,
    service_context=service_context
)
```

- Carica l'indice vettoriale da disco
- Persiste tra le sessioni
- Richiede che l'indice sia giÃ  stato creato

**Flow d'esecuzione**:

```
authenticate_huggingface()
    â†“
config.validate()
    â†“
LLM initialization (Ollama)
    â†“
Embedding model initialization (HuggingFace)
    â†“
ServiceContext creation
    â†“
Load vector store from disk
    â†“
Return query engine
```

---

### 3.4 INDEXER.PY - Creazione Indici Vettoriali

**Percorso**: `src/mistral/core/indexer.py`

**ResponsabilitÃ **:
- Legge lo schema SQL dal file `data/schema.sql`
- Crea un indice vettoriale ricercabile
- Persiste l'indice su disco per riutilizzo

**Funzione principale**:

```python
def create_index() -> None:
    """
    Create vector index from SQL schema.

    This function:
    1. Authenticates with HuggingFace
    2. Loads the SQL schema file
    3. Creates embeddings for the schema
    4. Persists the index to disk

    Raises:
        ValueError: If configuration is invalid
        FileNotFoundError: If schema file doesn't exist
    """
```

**Procedura**:

#### 1. Autenticazione e Validazione

```python
authenticate_huggingface()
config.validate()
```

#### 2. Inizializzazione Componenti

Stessa procedura di `engine.py`:
- LLM Ollama
- Embedding HuggingFace
- ServiceContext

#### 3. Caricamento Schema SQL

```python
documents = SimpleDirectoryReader(
    input_files=[str(config.SCHEMA_FILE)]
).load_data()
```

- Legge `data/schema.sql`
- Crea documenti indexabili

#### 4. Creazione Indice Vettoriale

```python
index = VectorStoreIndex.from_documents(
    documents,
    service_context=service_context
)
```

- Genera embeddings per ogni documento
- Crea struttura per ricerca semantica

#### 5. Persistenza

```python
index.storage_context.persist(
    persist_dir=str(config.VECTOR_STORE_DIR)
)
```

- Salva su `data/db_index/`
- Disponibile per `engine.py`

**Entry point**:

```python
def main() -> None:
    """Main entry point for index creation."""
    logging.basicConfig(level=logging.INFO)
    try:
        create_index()
        logger.info("Index created successfully")
    except Exception as e:
        logger.error(f"Failed to create index: {e}")
        raise
```

---

### 3.5 APP.PY - Applicazione Streamlit

**Percorso**: `src/mistral/ui/app.py`

**ResponsabilitÃ **:
- Orchestrazione della logica dell'applicazione
- Gestione dello stato della sessione
- Elaborazione delle query utente
- Gestione della cronologia

**Componenti principali**:

#### 1. Inizializzazione Sessione

```python
def initialize_session_state() -> None:
    """Initialize Streamlit session state."""
    if "query_engine" not in st.session_state:
        with st.spinner("Caricamento del query engine in corso..."):
            st.session_state.query_engine = load_query_engine()

    if "history" not in st.session_state:
        st.session_state.history = []
```

- Carica il query engine (una sola volta per sessione)
- Inizializza la cronologia delle query

#### 2. Elaborazione Query

```python
def process_user_query(user_query: str) -> None:
    """
    Process user query and display results.

    Args:
        user_query: Natural language query from user
    """
    try:
        start_time = time.time()
        response = st.session_state.query_engine.query(user_query)
        elapsed_time = time.time() - start_time

        st.session_state.history.append({
            "query": user_query,
            "response": str(response),
            "time": elapsed_time
        })

    except Exception as e:
        st.error(f"Errore durante l'elaborazione: {e}")
```

- Misura il tempo di risposta
- Esegue la query tramite il query engine
- Aggiunge alla cronologia
- Gestisce gli errori

#### 3. Main Entry Point

```python
def main() -> None:
    """Main application entry point."""
    logging.basicConfig(level=logging.INFO)

    setup_page_config()
    setup_custom_css()
    display_header()

    initialize_session_state()

    user_query = get_user_input()

    if user_query:
        process_user_query(user_query)

    if st.session_state.history:
        display_history(st.session_state.history)
```

**Flow dell'interfaccia**:

```
Setup Streamlit page
    â†“
Load query engine (if not already loaded)
    â†“
Display header
    â†“
Get user input (text area)
    â†“
User clicks "Genera query" button
    â†“
Process query (timing + execution)
    â†“
Add to history
    â†“
Display history (expandable items)
```

---

### 3.6 COMPONENTS.PY - Componenti UI

**Percorso**: `src/mistral/ui/components.py`

**ResponsabilitÃ **:
- Componenti UI riutilizzabili
- Rendering HTML/CSS personalizzato
- Estrazione e visualizzazione codice SQL
- Gestione copy-to-clipboard

**Funzioni principali**:

#### 1. `setup_page_config()`

Configurazione pagina Streamlit:

```python
def setup_page_config() -> None:
    """Configure Streamlit page settings."""
    st.set_page_config(
        page_title="Mistral SQL Assistant",
        page_icon="ðŸ¤–",
        layout="wide"
    )
```

#### 2. `setup_custom_css()`

CSS personalizzato per pulsanti:

```python
def setup_custom_css() -> None:
    """Apply custom CSS styles."""
    st.markdown("""
        <style>
        .stButton > button {
            background-color: #4CAF50;
            color: white;
        }
        </style>
    """, unsafe_allow_html=True)
```

#### 3. `display_header()`

Header principale con titolo:

```python
def display_header() -> None:
    """Display application header."""
    st.title("ðŸ¤– Mistral SQL Assistant")
    st.markdown("Chiedi in linguaggio naturale, ricevi query SQL!")
```

#### 4. `get_user_input()`

Text area per input utente:

```python
def get_user_input() -> str:
    """Get user input from text area."""
    user_query = st.text_area(
        "Inserisci la tua domanda:",
        height=100
    )

    if st.button("Genera query"):
        return user_query
    return ""
```

#### 5. `display_response_time()`

Mostra tempo di risposta:

```python
def display_response_time(elapsed_time: float) -> None:
    """Display query response time."""
    st.info(f"â±ï¸ Tempo di risposta: {elapsed_time:.2f} secondi")
```

#### 6. `display_history()`

Cronologia query espandibile:

```python
def display_history(history: list) -> None:
    """Display query history with expandable items."""
    st.subheader("ðŸ“š Cronologia")

    for i, item in enumerate(reversed(history)):
        with st.expander(f"Query {len(history) - i}: {item['query'][:50]}..."):
            st.write(f"**Domanda:** {item['query']}")
            _display_sql_code_blocks(item['response'])
            display_response_time(item['time'])
```

#### 7. `_display_sql_code_blocks()`

Estrae e visualizza blocchi SQL:

```python
def _display_sql_code_blocks(response: str) -> None:
    """Extract and display SQL code blocks."""
    match = re.search(r"```sql(.*?)```", response, re.DOTALL)
    if match:
        sql_code = match.group(1).strip()
        st.code(sql_code, language="sql")
        _add_copy_button(sql_code)
    else:
        st.write(response)
```

#### 8. `_add_copy_button()`

Pulsante copy to clipboard:

```python
def _add_copy_button(sql_code: str) -> None:
    """Add copy to clipboard button."""
    if st.button("ðŸ“‹ Copia query"):
        st.write("Query copiata!")
        # In production: use streamlit-copy-to-clipboard component
```

**Pattern di estrazione SQL**:

```python
match = re.search(r"```sql(.*?)```", response, re.DOTALL)
```

- Cerca blocchi SQL nel markdown
- Li visualizza con syntax highlighting

---

## 4. ARCHITETTURA DEL SISTEMA

### 4.1 Diagramma del Flusso Generale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     STREAMLIT FRONTEND                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Input utente (linguaggio naturale)                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                      â”‚                                      â”‚
â”‚                      â†“                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  app.py: process_user_query()                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   engine.py             â”‚
        â”‚ load_query_engine()     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚            â”‚                 â”‚
    â†“            â†“                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ollama  â”‚ â”‚ HuggingFace â”‚  â”‚ Vector Store â”‚
â”‚ Mistral â”‚ â”‚ Embeddings  â”‚  â”‚  (LlamaIndex)â”‚
â”‚  (LLM)  â”‚ â”‚  (Semantic) â”‚  â”‚  (Persistent)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚            â”‚                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Query Engine          â”‚
        â”‚ (Semantic Search +      â”‚
        â”‚  LLM Generation)        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   SQL Query Response    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              STREAMLIT FRONTEND (Display)                    â”‚
â”‚  - Response time visualization                              â”‚
â”‚  - SQL syntax highlighting                                  â”‚
â”‚  - Copy to clipboard functionality                          â”‚
â”‚  - Query history with expandable items                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Flusso di Autenticazione

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Application Start   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Load config.py                        â”‚
â”‚  - Load .env variables                 â”‚
â”‚  - Set up paths                        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  engine.py: load_query_engine()        â”‚
â”‚  â”œâ”€ authenticate_huggingface()         â”‚
â”‚  â””â”€ config.validate()                  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  auth.py: authenticate_huggingface()   â”‚
â”‚  â”œâ”€ Get token (param or config)        â”‚
â”‚  â”œâ”€ Validate token exists              â”‚
â”‚  â””â”€ login(token=hf_token)              â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“ (Success)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HuggingFace API                       â”‚
â”‚  Authenticate & authorize              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.3 Flusso di Creazione Indice

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  mistral-create-index        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  indexer.py: main()                â”‚
â”‚  â””â”€ create_index()                 â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Authenticate with HuggingFace     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Initialize:                       â”‚
â”‚  - LLM (Ollama)                    â”‚
â”‚  - Embedding Model (HuggingFace)   â”‚
â”‚  - ServiceContext                  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Load data/schema.sql              â”‚
â”‚  SimpleDirectoryReader             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Create Vector Index               â”‚
â”‚  VectorStoreIndex.from_documents() â”‚
â”‚  (Generates embeddings)            â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Persist Index                     â”‚
â”‚  â†’ data/db_index/                  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âœ… Index Ready for use             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.4 Pattern Architetturale: Separation of Concerns

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  UI Layer (app.py)                      â”‚
â”‚  - User interaction                                     â”‚
â”‚  - Streamlit components                                â”‚
â”‚  - Session management                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    â”‚ Core Layer                         â”‚
â”‚  engine.py         â”‚         indexer.py                 â”‚
â”‚  - Query           â”‚         - Index                    â”‚
â”‚    execution       â”‚           creation                 â”‚
â”‚  - Engine setup    â”‚         - Persistence             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        â”‚ Configuration Layer     â”‚                   â”‚
â”‚        â”‚                         â”‚                   â”‚
â”‚      config.py            auth.py                    â”‚
â”‚      - Settings           - HF Authentication        â”‚
â”‚      - Validation         - Token management         â”‚
â”‚      - Paths              - Error handling           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         External Services Layer                      â”‚
â”‚                                                      â”‚
â”‚  - Ollama (LLM)                                     â”‚
â”‚  - HuggingFace Hub (Embeddings)                     â”‚
â”‚  - File System (Persistence)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. AUTENTICAZIONE - DETTAGLI TECNICI

### 5.1 Come Funziona auth.py

**File**: `src/mistral/utils/auth.py`

**Scopo**: Gestire l'autenticazione con HuggingFace Hub per accedere ai modelli di embedding e altre risorse.

**Implementazione completa**:

```python
import logging
from typing import Optional
from huggingface_hub import login
from mistral import config

logger = logging.getLogger(__name__)

def authenticate_huggingface(token: Optional[str] = None) -> None:
    """
    Authenticate with HuggingFace Hub.

    Args:
        token: Optional HuggingFace token. If not provided,
               uses token from config.

    Raises:
        ValueError: If no token is available
        Exception: If authentication fails
    """
    # 1. Ottiene il token da parametro o da config
    hf_token = token or config.HUGGINGFACE_TOKEN

    # 2. Valida che il token sia disponibile
    if not hf_token:
        raise ValueError(
            "HuggingFace token is required. "
            "Set HUGGINGFACE_TOKEN environment variable or pass token parameter."
        )

    # 3. Esegue l'autenticazione
    try:
        login(token=hf_token)
        logger.info("Successfully authenticated with HuggingFace Hub")
    except Exception as e:
        logger.error(f"Failed to authenticate with HuggingFace Hub: {e}")
        raise
```

**Quando viene chiamato**:
- In `engine.py` (linea ~30): Prima di caricare il query engine
- In `indexer.py` (linea ~35): Prima di creare l'indice

**Cosa fa internamente**:

1. Importa `login` da `huggingface_hub`
2. Chiama `login(token=...)` per autenticarsi
3. Salva il token nel cache di HuggingFace (tipicamente `~/.huggingface/token`)
4. Da questo punto, le richieste a HuggingFace includono il token automaticamente

**Configurazione token**:

- **Fonte primaria**: Variabile d'ambiente `HUGGINGFACE_TOKEN` (da `.env`)
- **Fonte secondaria**: Parametro opzionale della funzione
- **Fallback**: Nessuno - solleva `ValueError` se assente

**Gestione errori**:

- Token mancante: `ValueError` con messaggio descrittivo
- Autenticazione fallita: Re-lancia l'eccezione da HuggingFace
- Registra tutti gli errori nei log

### 5.2 Token HuggingFace

Nel file `.env`:

```ini
HUGGINGFACE_TOKEN=
```

**Cos'Ã¨**: Token di accesso personale per l'API di HuggingFace

**Dove ottenere**: https://huggingface.co/settings/tokens

**Scopo**: Autenticazione per scaricare e usare modelli (anche privati)

**Sicurezza**:
- Non va commitato in git (incluso in `.gitignore`)
- Usare `.env.example` come template pubblico
- Rotazione periodica consigliata

### 5.3 Test di Autenticazione

File: `tests/test_auth.py`

```python
import pytest
from unittest.mock import patch, MagicMock
from mistral.utils.auth import authenticate_huggingface

class TestAuthentication:
    """Test suite for HuggingFace authentication."""

    @patch('mistral.utils.auth.login')
    @patch('mistral.utils.auth.config')
    def test_authenticate_with_config_token(self, mock_config, mock_login):
        """Test authentication using token from config."""
        mock_config.HUGGINGFACE_TOKEN = "config_token"
        authenticate_huggingface()
        mock_login.assert_called_once_with(token="config_token")

    @patch('mistral.utils.auth.login')
    def test_authenticate_with_parameter_token(self, mock_login):
        """Test authentication using token from parameter."""
        authenticate_huggingface(token="param_token")
        mock_login.assert_called_once_with(token="param_token")

    @patch('mistral.utils.auth.config')
    def test_authenticate_no_token_raises_error(self, mock_config):
        """Test that missing token raises ValueError."""
        mock_config.HUGGINGFACE_TOKEN = None
        with pytest.raises(ValueError, match="HuggingFace token is required"):
            authenticate_huggingface()

    @patch('mistral.utils.auth.login')
    def test_authenticate_login_failure(self, mock_login):
        """Test authentication failure handling."""
        mock_login.side_effect = Exception("Login failed")
        with pytest.raises(Exception, match="Login failed"):
            authenticate_huggingface(token="test_token")
```

**Coverage**: 100% della funzione `authenticate_huggingface()`

---

## 6. DIPENDENZE PRINCIPALI

**File**: `pyproject.toml`

### 6.1 Dipendenze di Produzione

```toml
[project]
dependencies = [
    "streamlit>=1.28.0",              # UI web framework
    "llama-index>=0.9.48",            # Vector indexing
    "langchain>=0.1.0",               # LLM abstraction
    "langchain-community>=0.0.10",    # Community LLM integrations
    "sentence-transformers>=2.2.0",   # Embedding models
    "setuptools",                     # Package setup utilities
    "huggingface-hub>=0.19.0",        # HuggingFace API
    "python-dotenv>=1.0.0",           # Environment variable loading
]
```

### 6.2 Tabella Dipendenze

| Pacchetto | Versione | Scopo | Note |
|-----------|----------|--------|------|
| **streamlit** | >=1.28.0 | Framework per interfaccia web interattiva | UI principale |
| **llama-index** | >=0.9.48 | Vector store e indexing dei documenti | Core del sistema |
| **langchain** | >=0.1.0 | Abstraction LLM e chain orchestration | Gestione LLM |
| **langchain-community** | >=0.0.10 | Integrazioni community (Ollama, etc) | Ollama support |
| **sentence-transformers** | >=2.2.0 | Modelli embedding semantici | all-MiniLM-L6-v2 |
| **huggingface-hub** | >=0.19.0 | API client per HuggingFace | Auth + download |
| **python-dotenv** | >=1.0.0 | Caricamento variabili d'ambiente | .env loading |
| **setuptools** | latest | Package setup utilities | Build support |

### 6.3 Dipendenze di Sviluppo

```toml
[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",           # Testing framework
    "pytest-asyncio>=0.21.0",  # Async test support
    "pytest-cov>=4.0.0",       # Coverage reporting
    "ruff>=0.1.0",             # Linter/formatter
    "mypy>=1.0.0",             # Type checking
    "pre-commit>=3.0.0",       # Git hooks
    "black>=23.0.0",           # Code formatter
]
```

### 6.4 Tabella Dipendenze Dev

| Pacchetto | Versione | Scopo |
|-----------|----------|--------|
| **pytest** | >=7.0.0 | Testing framework principale |
| **pytest-asyncio** | >=0.21.0 | Supporto test asincroni |
| **pytest-cov** | >=4.0.0 | Report coverage test |
| **ruff** | >=0.1.0 | Linter e formatter veloce |
| **mypy** | >=1.0.0 | Type checking statico |
| **pre-commit** | >=3.0.0 | Git hooks pre-commit |
| **black** | >=23.0.0 | Code formatter opinionated |

---

## 7. CONFIGURAZIONI E VARIABILI D'AMBIENTE

### 7.1 File .env

**File**: `.env` (e `.env.example` come template)

```ini
# ============================================
# HuggingFace Configuration
# ============================================
HUGGINGFACE_TOKEN=

# ============================================
# Device Configuration (cuda/cpu)
# ============================================
DEVICE=cpu

# ============================================
# Mistral Model Configuration
# ============================================
OLLAMA_MODEL=mistral
OLLAMA_HOST=host.docker.internal:11434

# ============================================
# Embedding Model Configuration
# ============================================
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# ============================================
# Vector Store Configuration
# ============================================
VECTOR_STORE_DIR=./data/db_index

# ============================================
# Streamlit Configuration
# ============================================
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=localhost
```

### 7.2 Dettagli Configurazioni

| Variabile | Default | Tipo | Descrizione | Obbligatorio |
|-----------|---------|------|-------------|--------------|
| `HUGGINGFACE_TOKEN` | - | string | Token API HuggingFace per modelli | âœ… SÃ¬ |
| `DEVICE` | `cuda` | string | CPU/GPU (`cuda` o `cpu`) per Embedding | No |
| `OLLAMA_MODEL` | `mistral` | string | Modello Ollama da usare | No |
| `OLLAMA_HOST` | `localhost:11434` | string | Host:Port server Ollama | No |
| `EMBEDDING_MODEL` | `all-MiniLM-L6-v2` | string | Modello embedding HuggingFace | No |
| `VECTOR_STORE_DIR` | `./data/db_index` | path | Directory per l'indice vettoriale | No |
| `STREAMLIT_SERVER_PORT` | `8501` | int | Porta server Streamlit | No |
| `STREAMLIT_SERVER_ADDRESS` | `localhost` | string | Indirizzo server Streamlit | No |

### 7.3 Validazione in config.py

```python
@classmethod
def validate(cls) -> None:
    """
    Validate configuration settings.

    Raises:
        ValueError: If HUGGINGFACE_TOKEN is not set
        FileNotFoundError: If schema file doesn't exist
    """
    # Validate required settings
    if not cls.HUGGINGFACE_TOKEN:
        raise ValueError(
            "HUGGINGFACE_TOKEN environment variable is required. "
            "Get your token at https://huggingface.co/settings/tokens"
        )

    # Validate files exist
    if not cls.SCHEMA_FILE.exists():
        raise FileNotFoundError(
            f"Schema file not found at: {cls.SCHEMA_FILE}. "
            "Please create data/schema.sql with your database schema."
        )

    # Create directories if they don't exist
    cls.VECTOR_STORE_DIR.mkdir(parents=True, exist_ok=True)
    cls.DATA_DIR.mkdir(parents=True, exist_ok=True)

    # Log configuration
    logger.info(f"Configuration validated successfully")
    logger.info(f"Using device: {cls.DEVICE}")
    logger.info(f"Using LLM: {cls.OLLAMA_MODEL}")
    logger.info(f"Using embedding model: {cls.EMBEDDING_MODEL}")
```

### 7.4 Best Practices

1. **Sicurezza**:
   - Non commitare mai il file `.env` nel repository
   - Usare `.env.example` come template pubblico
   - Rotare i token periodicamente

2. **Docker**:
   - In produzione usare variabili d'ambiente del container
   - In sviluppo montare `.env` come volume read-only

3. **Device Configuration**:
   - Usare `DEVICE=cuda` solo se hai GPU NVIDIA
   - Usare `DEVICE=cpu` per sviluppo su laptop
   - In Docker, `DEVICE=cpu` Ã¨ piÃ¹ portabile

---

## 8. PUNTI DI INGRESSO DELL'APPLICAZIONE

### 8.1 Entry Point Principale: Streamlit App

#### Metodo 1 - Script Console (raccomandato)

```bash
mistral-app
```

Definito in `pyproject.toml`:

```toml
[project.scripts]
mistral-app = "mistral.ui.app:main"
```

#### Metodo 2 - Script Python

```bash
python scripts/run_app.py
```

Contenuto di `scripts/run_app.py`:

```python
#!/usr/bin/env python3
"""Run the Mistral SQL Assistant application."""

from mistral.ui.app import main

if __name__ == "__main__":
    main()
```

#### Metodo 3 - Streamlit Diretto

```bash
streamlit run src/mistral/ui/app.py
```

#### Metodo 4 - Docker Compose (raccomandato per produzione)

```bash
docker-compose up --build
```

Accesso: http://localhost:8501

---

### 8.2 Entry Point Creazione Indice

#### Metodo 1 - Console Script (raccomandato)

```bash
mistral-create-index
```

Definito in `pyproject.toml`:

```toml
[project.scripts]
mistral-create-index = "mistral.core.indexer:main"
```

#### Metodo 2 - Script Python

```bash
python scripts/create_index.py
```

Contenuto di `scripts/create_index.py`:

```python
#!/usr/bin/env python3
"""Create vector index from SQL schema."""

from mistral.core.indexer import main

if __name__ == "__main__":
    main()
```

#### Metodo 3 - Modulo Diretto

```bash
python -m mistral.core.indexer
```

---

### 8.3 Entry Point Definition (pyproject.toml)

```toml
[project.scripts]
mistral-app = "mistral.ui.app:main"
mistral-create-index = "mistral.core.indexer:main"
```

Definisce due console script eseguibili dopo l'installazione:

- **`mistral-app`**: Esegue `main()` da `mistral/ui/app.py`
- **`mistral-create-index`**: Esegue `main()` da `mistral/core/indexer.py`

---

### 8.4 Flow di Avvio Completo (App)

```
1. USER RUNS: mistral-app (or docker-compose up)
                  â†“
2. Entry: src/mistral/ui/app.py::main()
                  â†“
3. logging.basicConfig(level=logging.INFO)
                  â†“
4. setup_page_config()
   - st.set_page_config(...)
                  â†“
5. setup_custom_css()
   - Apply custom styles
                  â†“
6. display_header()
   - st.title("ðŸ¤– Mistral SQL Assistant")
                  â†“
7. initialize_session_state()
   - Check if "query_engine" in st.session_state
   - If not:
     - load_query_engine()
       - authenticate_huggingface()
       - config.validate()
       - Initialize LLM (Ollama)
       - Initialize Embeddings (HuggingFace)
       - Load vector store from disk
   - Initialize history []
                  â†“
8. user_query = get_user_input()
   - Display text area for input
   - Display "Genera query" button
                  â†“
9. if user_query: (button clicked)
   - process_user_query(user_query)
     - start_time = time.time()
     - response = query_engine.query(user_query)
     - elapsed_time = time.time() - start_time
     - Add to history
                  â†“
10. if st.session_state.history:
    - display_history(history)
      - Show all past queries
      - Expandable items
      - SQL syntax highlighting
      - Copy to clipboard buttons
```

---

### 8.5 Flow di Creazione Indice (Indexer)

```
1. USER RUNS: mistral-create-index
                  â†“
2. Entry: src/mistral/core/indexer.py::main()
                  â†“
3. logging.basicConfig(level=logging.INFO)
                  â†“
4. try: create_index()
                  â†“
5. authenticate_huggingface()
   - Login to HuggingFace Hub
                  â†“
6. config.validate()
   - Check HUGGINGFACE_TOKEN
   - Check schema.sql exists
   - Create directories
                  â†“
7. Initialize LLM (Ollama)
   - llm = LangChainLLM(llm=Ollama(...))
                  â†“
8. Initialize Embedding Model (HuggingFace)
   - embed_model = HuggingFaceEmbedding(...)
                  â†“
9. Create ServiceContext
   - service_context = ServiceContext.from_defaults(...)
                  â†“
10. Load SQL Schema
    - documents = SimpleDirectoryReader(...).load_data()
    - Source: data/schema.sql
                  â†“
11. Create Vector Index
    - index = VectorStoreIndex.from_documents(...)
    - Generates embeddings for each document chunk
                  â†“
12. Persist Index
    - index.storage_context.persist(persist_dir=...)
    - Save to: data/db_index/
                  â†“
13. logger.info("Index created successfully")
                  â†“
14. Exit with code 0 (success)
```

---

## 9. SCHEMA SQL E KNOWLEDGE BASE

### 9.1 File Schema SQL

**File**: `data/schema.sql`

```sql
-- ============================================
-- DATABASE SCHEMA FOR SQL ASSISTANT
-- ============================================

-- Tabella Clienti
CREATE TABLE clienti (
  id INT PRIMARY KEY,
  nome VARCHAR(100),
  email VARCHAR(100)
);

-- Tabella Ordini
CREATE TABLE ordini (
  id INT PRIMARY KEY,
  cliente_id INT,
  data DATE,
  totale NUMERIC,
  FOREIGN KEY (cliente_id) REFERENCES clienti(id)
);

-- ============================================
-- ISTRUZIONI PER L'ASSISTENTE SQL
-- ============================================
-- Quando l'utente specifica periodi temporali
-- (es. "ultimi 30 giorni", "questo mese", "dal 2024"),
-- utilizzare SEMPRE il campo 'ordini.data' per filtrare temporalmente.
--
-- Esempi:
-- - "ordini di questo mese" â†’ WHERE EXTRACT(MONTH FROM data) = EXTRACT(MONTH FROM CURRENT_DATE)
-- - "ultimi 30 giorni" â†’ WHERE data >= CURRENT_DATE - INTERVAL '30 days'
-- - "dal 2024" â†’ WHERE EXTRACT(YEAR FROM data) >= 2024
-- ============================================
```

### 9.2 Scopo dello Schema

**Knowledge Base**:
- Definisce la struttura dei dati per il sistema
- Contiene le istruzioni per l'assistente SQL
- Base di conoscenza per la generazione di query

**Componenti**:

1. **Definizione Tabelle**:
   - `clienti`: Anagrafe clienti (id, nome, email)
   - `ordini`: Ordini dei clienti con relazione FK

2. **Istruzioni per l'LLM**:
   - Commenti SQL che guidano la generazione di query
   - Esempi di pattern temporali
   - Best practices specifiche del dominio

### 9.3 Come Viene Usato

```
data/schema.sql
    â†“
indexer.py: SimpleDirectoryReader
    â†“
Chunking e embedding generation
    â†“
Vector Store (data/db_index/)
    â†“
Semantic Search durante le query
    â†“
Recupera contesto rilevante
    â†“
Passa al LLM per generazione SQL
```

### 9.4 Personalizzazione

Per adattare il sistema al tuo database:

1. Modifica `data/schema.sql` con il tuo schema reale
2. Aggiungi commenti con istruzioni specifiche
3. Rigenera l'indice: `mistral-create-index`
4. Riavvia l'applicazione

**Esempio di personalizzazione**:

```sql
-- Tabella Prodotti
CREATE TABLE prodotti (
  id INT PRIMARY KEY,
  nome VARCHAR(200),
  categoria VARCHAR(50),
  prezzo NUMERIC(10,2),
  scorte INT
);

-- ISTRUZIONI:
-- Per query sulle scorte, usare sempre:
-- - scorte = 0 per prodotti esauriti
-- - scorte < 10 per prodotti in esaurimento
-- - scorte >= 10 per disponibilitÃ  normale
```

---

## 10. STRUTTURA DOCKER

### 10.1 Dockerfile

**File**: `Dockerfile`

```dockerfile
# ============================================
# Base Image
# ============================================
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# ============================================
# Install System Dependencies
# ============================================
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# ============================================
# Install uv (fast Python package manager)
# ============================================
RUN pip install uv

# ============================================
# Create non-root user for security
# ============================================
RUN useradd --create-home --shell /bin/bash mistral
RUN chown -R mistral:mistral /app
USER mistral

# ============================================
# Copy Dependency Files
# ============================================
COPY pyproject.toml uv.lock README.md ./

# ============================================
# Install Python Dependencies
# ============================================
RUN uv sync --frozen

# ============================================
# Copy Source Code
# ============================================
COPY src/ ./src/
COPY scripts/ ./scripts/
COPY data/ ./data/

# ============================================
# Expose Streamlit Port
# ============================================
EXPOSE 8501

# ============================================
# Health Check
# ============================================
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8501/_stcore/health || exit 1

# ============================================
# Run the Application
# ============================================
CMD ["uv", "run", "streamlit", "run", "src/mistral/ui/app.py", \
     "--server.port=8501", "--server.address=0.0.0.0"]
```

### 10.2 Caratteristiche Dockerfile

| Feature | Descrizione |
|---------|-------------|
| **Base Image** | `python:3.11-slim` - Leggera e ottimizzata |
| **Package Manager** | `uv` - Installazione dipendenze velocissima |
| **Security** | Non-root user `mistral` per maggiore sicurezza |
| **Health Check** | Monitoring endpoint Streamlit |
| **Port** | 8501 esposto per l'interfaccia web |

---

### 10.3 docker-compose.yml

**File**: `docker-compose.yml`

```yaml
version: '3.8'

services:
  mistral-app:
    build: .
    container_name: mistral-sql-assistant

    # Port Mapping
    ports:
      - "8501:8501"

    # Environment Variables
    environment:
      - PYTHONPATH=/app/src

    # Volume Mounts
    volumes:
      - ./.env:/app/.env:ro           # Config (read-only)
      - ./data:/app/data              # Persistent data
      - ./src:/app/src                # Hot reload (dev)

    # Restart Policy
    restart: unless-stopped

    # Health Check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
```

### 10.4 Volumi Docker

| Volume | Source | Destination | Mode | Scopo |
|--------|--------|-------------|------|-------|
| **Config** | `./.env` | `/app/.env` | `ro` | Variabili d'ambiente (read-only) |
| **Data** | `./data` | `/app/data` | `rw` | Schema SQL + indici vettoriali persistenti |
| **Source** | `./src` | `/app/src` | `rw` | Hot reload durante sviluppo |

### 10.5 Comandi Docker

#### Build e Start

```bash
# Build image e avvia container
docker-compose up --build

# Avvia in background (detached)
docker-compose up -d

# Build senza cache
docker-compose build --no-cache
```

#### Management

```bash
# Stop containers
docker-compose down

# View logs
docker-compose logs -f

# Restart
docker-compose restart

# Remove volumes (reset data)
docker-compose down -v
```

#### Debug

```bash
# Shell nel container
docker-compose exec mistral-app bash

# Check health
docker-compose ps

# Inspect container
docker inspect mistral-sql-assistant
```

---

## 11. TESTING

### 11.1 Framework e Struttura

**Framework**: pytest

```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ conftest.py          # Pytest fixtures globali
â”œâ”€â”€ test_auth.py         # Test autenticazione
â””â”€â”€ test_config.py       # Test configurazione
```

### 11.2 Configurazione Pytest

**File**: `pyproject.toml`

```toml
[tool.pytest.ini_options]
minversion = "7.0"
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = [
    "-v",                    # Verbose
    "--strict-markers",      # Strict marker checking
    "--tb=short",           # Short traceback format
    "--cov=mistral",        # Coverage for mistral package
    "--cov-report=term-missing",  # Show missing lines
    "--cov-report=html",    # HTML coverage report
]
```

### 11.3 Test Execution

#### Comandi Base

```bash
# Run all tests
pytest

# Run with verbose output
pytest -v

# Run specific test file
pytest tests/test_auth.py

# Run specific test
pytest tests/test_auth.py::TestAuthentication::test_authenticate_with_config_token

# Run with specific marker
pytest -m unit
```

#### Coverage

```bash
# Run with coverage
pytest --cov=mistral

# Coverage with HTML report
pytest --cov=mistral --cov-report=html

# View HTML report
open htmlcov/index.html
```

#### Debug

```bash
# Run with pdb on failure
pytest --pdb

# Stop on first failure
pytest -x

# Show local variables on failure
pytest -l
```

### 11.4 Fixtures (conftest.py)

**File**: `tests/conftest.py`

```python
import pytest
from unittest.mock import MagicMock
from pathlib import Path

@pytest.fixture
def mock_config():
    """Mock configuration for tests."""
    config = MagicMock()
    config.HUGGINGFACE_TOKEN = "test_token"
    config.DEVICE = "cpu"
    config.OLLAMA_MODEL = "mistral"
    config.OLLAMA_HOST = "localhost:11434"
    config.EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
    config.VECTOR_STORE_DIR = Path("./test_data/db_index")
    config.SCHEMA_FILE = Path("./test_data/schema.sql")
    return config

@pytest.fixture
def sample_query():
    """Sample query for testing."""
    return "Quanti ordini ho fatto questo mese?"

@pytest.fixture
def sample_response():
    """Sample SQL response for testing."""
    return """
    ```sql
    SELECT COUNT(*)
    FROM ordini
    WHERE EXTRACT(MONTH FROM data) = EXTRACT(MONTH FROM CURRENT_DATE)
    ```
    """

@pytest.fixture
def mock_query_engine():
    """Mock query engine for testing."""
    engine = MagicMock()
    engine.query.return_value = "SELECT * FROM users"
    return engine
```

### 11.5 Test Suite Examples

#### Test Authentication (test_auth.py)

```python
import pytest
from unittest.mock import patch, MagicMock
from mistral.utils.auth import authenticate_huggingface

class TestAuthentication:
    """Test suite for HuggingFace authentication."""

    @patch('mistral.utils.auth.login')
    @patch('mistral.utils.auth.config')
    def test_authenticate_with_config_token(self, mock_config, mock_login):
        """Test authentication using token from config."""
        mock_config.HUGGINGFACE_TOKEN = "config_token"
        authenticate_huggingface()
        mock_login.assert_called_once_with(token="config_token")

    @patch('mistral.utils.auth.login')
    def test_authenticate_with_parameter_token(self, mock_login):
        """Test authentication using token from parameter."""
        authenticate_huggingface(token="param_token")
        mock_login.assert_called_once_with(token="param_token")

    @patch('mistral.utils.auth.config')
    def test_authenticate_no_token_raises_error(self, mock_config):
        """Test that missing token raises ValueError."""
        mock_config.HUGGINGFACE_TOKEN = None
        with pytest.raises(ValueError, match="HuggingFace token is required"):
            authenticate_huggingface()

    @patch('mistral.utils.auth.login')
    def test_authenticate_login_failure(self, mock_login):
        """Test authentication failure handling."""
        mock_login.side_effect = Exception("Login failed")
        with pytest.raises(Exception, match="Login failed"):
            authenticate_huggingface(token="test_token")
```

#### Test Configuration (test_config.py)

```python
import pytest
from unittest.mock import patch
from mistral.config import Config

class TestConfiguration:
    """Test suite for configuration validation."""

    def test_config_loads_environment_variables(self):
        """Test that config loads from environment."""
        with patch.dict('os.environ', {
            'HUGGINGFACE_TOKEN': 'test_token',
            'DEVICE': 'cpu'
        }):
            assert Config.HUGGINGFACE_TOKEN == 'test_token'
            assert Config.DEVICE == 'cpu'

    def test_validate_raises_error_without_token(self):
        """Test validation fails without token."""
        with patch.object(Config, 'HUGGINGFACE_TOKEN', ''):
            with pytest.raises(ValueError, match="HUGGINGFACE_TOKEN"):
                Config.validate()

    def test_validate_creates_directories(self, tmp_path):
        """Test that validate creates necessary directories."""
        with patch.object(Config, 'VECTOR_STORE_DIR', tmp_path / 'db_index'):
            with patch.object(Config, 'HUGGINGFACE_TOKEN', 'test'):
                with patch.object(Config, 'SCHEMA_FILE', tmp_path / 'schema.sql'):
                    (tmp_path / 'schema.sql').touch()
                    Config.validate()
                    assert (tmp_path / 'db_index').exists()
```

### 11.6 Test Coverage Goals

| Module | Target Coverage | Current |
|--------|----------------|---------|
| `auth.py` | 100% | 100% |
| `config.py` | 90% | 85% |
| `engine.py` | 80% | 70% |
| `indexer.py` | 80% | 75% |
| `app.py` | 70% | 60% |
| `components.py` | 70% | 65% |

---

## 12. CODICE DI CONFIGURAZIONE QUALITÃ€

### 12.1 Ruff (Linting/Formatting)

**File**: `pyproject.toml`

```toml
[tool.ruff]
target-version = "py310"
line-length = 88

# Enable rules
select = [
    "E",   # pycodestyle errors
    "W",   # pycodestyle warnings
    "F",   # pyflakes
    "I",   # isort
    "B",   # flake8-bugbear
    "C4",  # flake8-comprehensions
    "UP",  # pyupgrade
]

# Ignore rules
ignore = [
    "E501",  # line too long (handled by black)
]

# Exclude patterns
exclude = [
    ".git",
    ".venv",
    "__pycache__",
    "build",
    "dist",
]

[tool.ruff.per-file-ignores]
"__init__.py" = ["F401"]  # Allow unused imports in __init__.py
```

**Comandi**:

```bash
# Check code
ruff check .

# Auto-fix issues
ruff check --fix .

# Format code
ruff format .
```

---

### 12.2 MyPy (Type Checking)

**File**: `pyproject.toml`

```toml
[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true
strict_equality = true

# Per-module options
[[tool.mypy.overrides]]
module = "tests.*"
disallow_untyped_defs = false
```

**Comandi**:

```bash
# Type check entire codebase
mypy src/

# Type check specific file
mypy src/mistral/utils/auth.py

# Generate HTML report
mypy --html-report mypy-report src/
```

---

### 12.3 Black (Code Formatter)

**File**: `pyproject.toml`

```toml
[tool.black]
line-length = 88
target-version = ['py310', 'py311']
include = '\.pyi?$'
extend-exclude = '''
/(
  # directories
  \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | build
  | dist
)/
'''
```

**Comandi**:

```bash
# Format entire codebase
black src/ tests/

# Check without formatting
black --check src/

# Format specific file
black src/mistral/ui/app.py
```

---

### 12.4 Pre-commit Hooks

**File**: `.pre-commit-config.yaml`

```yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files

  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.1.0
    hooks:
      - id: ruff
        args: [--fix, --exit-non-zero-on-fix]

  - repo: https://github.com/psf/black
    rev: 23.11.0
    hooks:
      - id: black

  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.7.0
    hooks:
      - id: mypy
        additional_dependencies: [types-all]
```

**Setup**:

```bash
# Install pre-commit hooks
pre-commit install

# Run manually on all files
pre-commit run --all-files

# Update hooks
pre-commit autoupdate
```

---

### 12.5 Quality Workflow

```
Developer commits code
        â†“
Pre-commit hooks run automatically
        â†“
1. trailing-whitespace check
2. end-of-file-fixer
3. check-yaml
4. ruff (lint + auto-fix)
5. black (format)
6. mypy (type check)
        â†“
All checks pass?
    â”œâ”€ Yes â†’ Commit proceeds
    â””â”€ No â†’ Commit blocked, fix issues
        â†“
CI/CD pipeline (if configured)
    â”œâ”€ Run pytest
    â”œâ”€ Coverage report
    â”œâ”€ Ruff check
    â”œâ”€ MyPy check
    â””â”€ Build Docker image
```

---

## 13. RIASSUNTO ARCHITETTURALE

### 13.1 Flusso Completo dall'Inizio alla Fine

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. STARTUP PHASE                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ User runs: docker-compose up                                â”‚
â”‚   â†“                                                          â”‚
â”‚ Docker builds image & starts container                      â”‚
â”‚   â†“                                                          â”‚
â”‚ Streamlit app.py::main() starts                            â”‚
â”‚   â†“                                                          â”‚
â”‚ config.py loads .env variables                             â”‚
â”‚   â†“                                                          â”‚
â”‚ Displays Streamlit UI                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. FIRST QUERY EXECUTION (Session Initialization)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ User clicks "Genera query"                                  â”‚
â”‚   â†“                                                          â”‚
â”‚ app.py::initialize_session_state()                          â”‚
â”‚   â”œâ”€ engine.py::load_query_engine()                        â”‚
â”‚   â”‚   â”œâ”€ auth.py::authenticate_huggingface()               â”‚
â”‚   â”‚   â”œâ”€ config.validate()                                 â”‚
â”‚   â”‚   â”œâ”€ Initialize Ollama LLM                             â”‚
â”‚   â”‚   â”œâ”€ Initialize HuggingFace Embeddings                 â”‚
â”‚   â”‚   â””â”€ Load vector store from data/db_index/             â”‚
â”‚   â””â”€ Initialize history list                               â”‚
â”‚   â†“                                                          â”‚
â”‚ st.session_state.query_engine loaded                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. QUERY PROCESSING (Every Query)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ User input: "Quanti ordini ho fatto questo mese?"          â”‚
â”‚   â†“                                                          â”‚
â”‚ app.py::process_user_query(user_query)                      â”‚
â”‚   â”œâ”€ Start timer                                            â”‚
â”‚   â”œâ”€ query_engine.query(user_query)                        â”‚
â”‚   â”‚   â”œâ”€ HuggingFace converts query to embedding vector    â”‚
â”‚   â”‚   â”œâ”€ Semantic search in vector store                   â”‚
â”‚   â”‚   â”œâ”€ Retrieves relevant schema parts                   â”‚
â”‚   â”‚   â”œâ”€ Passes to Ollama LLM with prompt                 â”‚
â”‚   â”‚   â”œâ”€ LLM generates SQL query with instructions         â”‚
â”‚   â”‚   â””â”€ Returns: "SELECT COUNT(*) FROM ordini WHERE..."   â”‚
â”‚   â”œâ”€ Stop timer, measure response time                     â”‚
â”‚   â”œâ”€ Add to history                                         â”‚
â”‚   â””â”€ Display response + timing                             â”‚
â”‚   â†“                                                          â”‚
â”‚ components.py::display_history()                            â”‚
â”‚   â”œâ”€ Show response time                                     â”‚
â”‚   â”œâ”€ Display full response in text area                     â”‚
â”‚   â”œâ”€ Extract SQL block with regex                          â”‚
â”‚   â”œâ”€ Display SQL with syntax highlighting                  â”‚
â”‚   â””â”€ Show copy-to-clipboard button                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. INDEX CREATION (One-time, Before Usage)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ User runs: mistral-create-index                             â”‚
â”‚   â†“                                                          â”‚
â”‚ indexer.py::main()::create_index()                          â”‚
â”‚   â”œâ”€ auth.py::authenticate_huggingface()                   â”‚
â”‚   â”œâ”€ Initialize Ollama LLM                                  â”‚
â”‚   â”œâ”€ Initialize HuggingFace Embeddings                      â”‚
â”‚   â”œâ”€ Load data/schema.sql                                   â”‚
â”‚   â”œâ”€ Create vector index from documents                     â”‚
â”‚   â”‚   â””â”€ Generate embeddings for each document part        â”‚
â”‚   â”œâ”€ Persist to data/db_index/                             â”‚
â”‚   â””â”€ Ready for engine.py to load                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 13.2 Pattern di Design Utilizzati

#### 1. Separation of Concerns

```
UI Layer        â†’ Presentazione e interazione utente
Core Layer      â†’ Logica business e orchestrazione
Config Layer    â†’ Configurazione e setup
External Layer  â†’ Servizi esterni (Ollama, HuggingFace)
```

#### 2. Singleton Pattern

```python
# Session state in Streamlit
if "query_engine" not in st.session_state:
    st.session_state.query_engine = load_query_engine()
```

Query engine caricato una sola volta per sessione.

#### 3. Factory Pattern

```python
# ServiceContext factory
service_context = ServiceContext.from_defaults(
    llm=llm,
    embed_model=embed_model
)
```

#### 4. Strategy Pattern

Diversi device strategies (CPU/GPU):

```python
embed_model = HuggingFaceEmbedding(
    model_name=config.EMBEDDING_MODEL,
    device=config.DEVICE  # "cuda" or "cpu"
)
```

---

### 13.3 Vantaggi dell'Architettura

1. **ModularitÃ **: Ogni componente ha una responsabilitÃ  specifica
2. **TestabilitÃ **: Facile creare unit test con mocking
3. **ManutenibilitÃ **: Modifiche isolate non impattano altri moduli
4. **ScalabilitÃ **: Facile aggiungere nuove feature
5. **RiusabilitÃ **: Componenti riutilizzabili in altri progetti
6. **ConfigurabilitÃ **: Tutto configurabile via environment variables

---

### 13.4 Tecnologie Chiave e PerchÃ©

| Tecnologia | PerchÃ© Utilizzata |
|------------|-------------------|
| **Streamlit** | RapiditÃ  sviluppo UI, interattivitÃ  senza frontend |
| **Ollama** | LLM locale, privacy, no API costs |
| **LlamaIndex** | Best-in-class per RAG e vector search |
| **HuggingFace** | Ecosistema completo embedding models |
| **uv** | Package manager velocissimo |
| **Docker** | PortabilitÃ , deployment consistente |
| **pytest** | Standard de-facto per testing Python |

---

### 13.5 Performance Considerations

#### Ottimizzazioni Implementate

1. **Persistent Vector Store**: Indice salvato su disco, non rigenerato ogni volta
2. **Session Caching**: Query engine caricato una volta per sessione
3. **CPU/GPU Flexibility**: Configurabile per diverse risorse hardware
4. **Lightweight Embedding Model**: all-MiniLM-L6-v2 (piccolo ma performante)
5. **Docker Multi-stage**: Build ottimizzato per produzione

#### Bottleneck Potenziali

1. **Prima query**: Caricamento modelli (30-60 secondi)
2. **Query processing**: Dipende da Ollama response time (2-5 secondi)
3. **Index creation**: One-time operation (1-2 minuti)

---

## 14. CONCLUSIONI

### 14.1 Recap Funzionale

**Mistral SQL Assistant** Ã¨ un'applicazione completa che:

1. âœ… Traduce linguaggio naturale in SQL
2. âœ… Usa modelli AI locali (privacy-first)
3. âœ… Persistenza dati tra sessioni
4. âœ… Interfaccia web user-friendly
5. âœ… Containerizzato e portabile
6. âœ… Ben testato e documentato

### 14.2 Punti di Forza

- **Privacy**: Tutto eseguito localmente
- **Customizable**: Facilmente adattabile a diversi schemi
- **Production-ready**: Docker, tests, type checking
- **Modern stack**: Tecnologie all'avanguardia
- **Developer-friendly**: Codice pulito e ben documentato

### 14.3 Possibili Miglioramenti Futuri

1. **Database Connection**: Eseguire query generate su database reale
2. **Query Validation**: Validare SQL prima di eseguirlo
3. **Multi-user**: Supporto sessioni multiple
4. **Advanced UI**: Chart visualizations, query builder
5. **More LLMs**: Supporto altri modelli (GPT-4, Claude, etc.)
6. **Caching**: Cache query frequenti
7. **Analytics**: Tracking usage patterns

---

**Fine Analisi**

Questo documento fornisce un'analisi completa e approfondita del progetto Mistral SQL Assistant, coprendo tutti gli aspetti dall'architettura al deployment, dai test alla configurazione.
